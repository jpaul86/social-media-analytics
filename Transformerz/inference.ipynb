{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love you</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate you</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I loved the music, but the story is poor.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text     label     score\n",
       "0                                 I love you  POSITIVE  0.999866\n",
       "1                                 I hate you  NEGATIVE  0.999113\n",
       "2  I loved the music, but the story is poor.  NEGATIVE  0.999332"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "sents = [\"I love you\", \"I hate you\",\n",
    "         \"I loved the music, but the story is poor.\"]\n",
    "results = classifier(sents)\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.DataFrame(sents, columns=['text']),\n",
    "    pd.DataFrame(results)\n",
    "], axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9685909748077393},\n",
       " {'label': 'negative', 'score': 0.9926037192344666},\n",
       " {'label': 'negative', 'score': 0.8034197092056274}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# German\n",
    "modelname = 'oliverguhr/german-sentiment-bert'\n",
    "classifier = pipeline(\"sentiment-analysis\", model=modelname)\n",
    "sents = [\"Liebe Freude und Glück\", \"Ich hasse dich\",\n",
    "         \"Ich liebe die Musik, aber der Plot ist eher dürftig.\"]\n",
    "classifier(sents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token classification (>1GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-ORG',\n",
       "  'score': 0.9974419,\n",
       "  'index': 1,\n",
       "  'word': 'European',\n",
       "  'start': 0,\n",
       "  'end': 8},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9983657,\n",
       "  'index': 2,\n",
       "  'word': 'Union',\n",
       "  'start': 9,\n",
       "  'end': 14},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.9993268,\n",
       "  'index': 12,\n",
       "  'word': 'Russian',\n",
       "  'start': 60,\n",
       "  'end': 67},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.99934334,\n",
       "  'index': 23,\n",
       "  'word': 'Russian',\n",
       "  'start': 118,\n",
       "  'end': 125},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9996989,\n",
       "  'index': 29,\n",
       "  'word': 'Ukraine',\n",
       "  'start': 150,\n",
       "  'end': 157},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9997489,\n",
       "  'index': 55,\n",
       "  'word': 'Hungary',\n",
       "  'start': 278,\n",
       "  'end': 285}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier = pipeline('token-classification')\n",
    "text = \"European Union countries finally reached a deal to wean off Russian oil, their most significant effort yet to hit the Russian economy over the war in Ukraine, though the impact will be softened by an exemption for pipeline oil, a concession to landlocked holdouts, most notably Hungary.\"\n",
    "token_classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization (>1GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' EU countries reach deal to wean off Russian oil, most significant effort yet to hit'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(text, min_length=5, max_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'the answer to life, the universe and everything'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2text_generator = pipeline(\"text2text-generation\")\n",
    "text2text_generator(\n",
    "    \"question: What is 42 ? context: 42 is the answer to life, the universe and everything\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill-Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10731089860200882,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello i'm a fashion model.\"},\n",
       " {'score': 0.08774491399526596,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello i'm a role model.\"},\n",
       " {'score': 0.05338399112224579,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello i'm a new model.\"},\n",
       " {'score': 0.046672288328409195,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello i'm a super model.\"},\n",
       " {'score': 0.027095867320895195,\n",
       "  'token': 2986,\n",
       "  'token_str': 'fine',\n",
       "  'sequence': \"hello i'm a fine model.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "724fee47540c5352669e3f4da2ce2047cbc31d5812c3a8db4034636254b0d2c2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
